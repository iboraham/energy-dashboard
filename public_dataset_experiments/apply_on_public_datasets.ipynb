{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from load_dataset import TimeSeries\n",
    "import numpy as np\n",
    "from annot_finder import annot_finder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Import methods\n",
    "from cpfinder.methods import bocpd, rulsif\n",
    "\n",
    "# Vis\n",
    "from vis import plot_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import evaluation metrics\n",
    "import cpfinder.eval_metrics as EVM\n",
    "from cpfinder.feature_engineering import _get_cps_from_R\n",
    "\n",
    "\n",
    "# Dataset folder \n",
    "DATA_PATH = \"../../Light data/TCPD/datasets\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#  List all the dataset names\n",
    "import pathlib\n",
    "import json \n",
    "\n",
    "datasets = list(pathlib.Path(DATA_PATH).glob('*'))\n",
    "annots_file = list(pathlib.Path(os.path.dirname(pathlib.Path(DATA_PATH))).glob('annot*.json'))[0]\n",
    "print(datasets[:3],len(datasets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[PosixPath('../../Light data/TCPD/datasets/apple'), PosixPath('../../Light data/TCPD/datasets/bee_waggle_6'), PosixPath('../../Light data/TCPD/datasets/shanghai_license')] 43\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Find all json files in folders\n",
    "data_files = []\n",
    "for data_folder in datasets:\n",
    "    data_files.extend(list(data_folder.glob(\"*.json\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from cpfinder.methods import online_changepoint_detection as oncd\n",
    "from collections import Counter\n",
    "\n",
    "# Operate over files\n",
    "\n",
    "\n",
    "f_measures = []\n",
    "cms = []\n",
    "hazard = 1 / 100\n",
    "mean0 = 0\n",
    "var0 = 1\n",
    "varx = 2\n",
    "\n",
    "model = oncd.GaussianUnknownMean(mean0, var0, varx)\n",
    "\n",
    "for dfile in tqdm(data_files):\n",
    "    # dfile = data_files[0]\n",
    "    ts = TimeSeries.from_json(dfile)\n",
    "    n_dim = ts.y.shape[1]\n",
    "    annots = annot_finder(dfile, annots_file)\n",
    "    all_annots=[]\n",
    "    for a in annots.keys():\n",
    "        all_annots.extend(annots[a])\n",
    "    best_annot = Counter(all_annots).most_common(1)[0][0]\n",
    "    vals = ts.y[:,0]\n",
    "    n_obs = len(vals)\n",
    "    R, pmean, pvar = oncd.online_changepoint_detection(vals, model, hazard)\n",
    "    # cps = _get_cps_from_R(R)\n",
    "    # f = EVM.f_measure(annots, cps)\n",
    "    # cm = EVM.covering(annots, cps, n_obs)\n",
    "    # f_measures.extend([f])\n",
    "    # cms.extend([cm])\n",
    "    # print(f\"\\n{ts.name} -----> f1 = {f}, covering = {cm} \\n  ---------- TOTAL: f1_mean = {np.mean(f_measures)}, covering_mean = {np.mean(cms)}\")\n",
    "    plot_matplotlib(vals, ts.t, R, pmean, pvar, [best_annot] , ts, True, f'results_bocpd/{ts.name}.jpg')\n",
    "    # fig.subplots_adjust(top=.95)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import roerich\n",
    "import numpy as np\n",
    "\n",
    "f_measures = []\n",
    "cms = []\n",
    "for dfile in tqdm(data_files):\n",
    "    ts = TimeSeries.from_json(dfile)\n",
    "    annots = annot_finder(dfile, annots_file)\n",
    "\n",
    "    n_dim = ts.y.shape[1]\n",
    "    for i in range(n_dim):\n",
    "        vals = ts.y[:,i].flatten()\n",
    "        n_obs = len(vals)\n",
    "        T = ts.t\n",
    "        cpd = roerich.OnlineNNRuLSIF(net='default', scaler=\"default\", \n",
    "                  metric=\"KL_sym\", # KL_sym, KL, JSD, PE, PE_sym, Wasserstein\n",
    "                  periods=2, # A number of previous data-points used when constructing autoregressive matrix\n",
    "                  window_size=200, # A size of a window when splitting input data into train and test arrays\n",
    "                  lag_size= 500, # A distance between train- and test- windows\n",
    "                  step=20, # Each `step`-th data-point is used when creating the input dataset\n",
    "                  n_epochs=8, # A number of epochs during training NN\n",
    "                  lr=0.0005, # A learning rate at each step of optimizer\n",
    "                  lam=0.01, # A regularization rate\n",
    "                  optimizer=\"ASGD\", # One of Adam, SGD, RMSprop or ASGD optimizers, \n",
    "                  debug = 0, # default zero\n",
    "                  alpha=1\n",
    "                 )\n",
    "        \n",
    "        try:\n",
    "            score, peaks = cpd.predict(vals)\n",
    "            f = EVM.f_measure(annots, peaks)\n",
    "            cm = EVM.covering(annots, peaks, n_obs)\n",
    "            f_measures.extend([f])\n",
    "            cms.extend([cm])\n",
    "            print(f\"\\n{ts.name} -----> f1 = {f}, covering = {cm} \\n  ---------- TOTAL: f1_mean = {np.mean(f_measures)}, covering_mean = {np.mean(cms)}\")\n",
    "        except ValueError:\n",
    "            peaks=[]\n",
    "            f = EVM.f_measure(annots, peaks)\n",
    "            cm = EVM.covering(annots, peaks, n_obs)\n",
    "            f_measures.extend([f])\n",
    "            cms.extend([cm])\n",
    "            print(f\"\\n{ts.name} -----> f1 = {f}, covering = {cm} \\n  ---------- TOTAL: f1_mean = {np.mean(f_measures)}, covering_mean = {np.mean(cms)}\")\n",
    "            continue\n",
    "        vals = vals.reshape(-1,1)\n",
    "        roerich.display(vals, T, annots, score, T, peaks)\n",
    "        try:\n",
    "            plt.savefig(f'results_rulsif/{ts.name}_dim_{i}.jpg', optimize=True)\n",
    "        except FileNotFoundError:\n",
    "            !mkdir results_rulsif\n",
    "            plt.savefig(f'results_rulsif/{ts.name}.jpg', optimize=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from parameter_search import parameter_search_rulsif\n",
    "\n",
    "search_space = {\n",
    "    \"net\": \"default\",\n",
    "    \"scaler\": \"default\",\n",
    "    \"metric\": [\"KL_sym\", \"KL\", \"JSD\"],\n",
    "    \"periods\": [1, 5, 10, 100],\n",
    "    \"window_size\": [10, 100, 250],\n",
    "    \"lag_size\": [100, 500, 1000],\n",
    "    \"step\": [20],\n",
    "    \"n_epochs\": [8],\n",
    "    \"lr\": [0.0005],\n",
    "    \"lam\": [0.01],\n",
    "    \"optimizer\": [\"Adam\"],\n",
    "    \"alpha\": [1],\n",
    "}\n",
    "\n",
    "dfile = data_files[0]\n",
    "ts = TimeSeries.from_json(dfile)\n",
    "annots = annot_finder(dfile, annots_file)\n",
    "vals = ts.y[:,0].flatten()\n",
    "parameter_search_rulsif(search_space, vals, eval_metric=EVM.f_measure, annotations=annots)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}